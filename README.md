# âš¡ Fast Video OCR - Extract Text from Video Frames

Speed-optimized Chrome extension + Python backend for extracting text from video frames using Tesseract OCR.

---

## ğŸ“‹ Features

- âœ… Extract text from any HTML5 video (YouTube, Twitch, Zoom, local files)
- âœ… Client-side preprocessing (grayscale + contrast) for 66% smaller uploads
- âœ… Fast Tesseract OCR (40-80ms processing time)
- âœ… Auto-copy to clipboard
- âœ… Keyboard shortcuts (Alt+Shift+S to activate)
- âœ… Works with SD/720p and HD video
- âœ… Privacy-focused (no data storage, no analytics)

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+ with pip
- Tesseract OCR 5.x
- Chrome/Chromium browser
- Node.js (optional, for development)

### 1. Install Tesseract OCR

**Ubuntu/Debian:**
```bash
sudo apt-get update
sudo apt-get install tesseract-ocr tesseract-ocr-eng libtesseract-dev
```

**macOS:**
```bash
brew install tesseract
```

**Windows:**
Download installer from https://github.com/UB-Mannheim/tesseract/wiki

Verify installation:
```bash
tesseract --version
```

### 2. Setup Backend

```bash
cd backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run server
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

Backend will start at `http://localhost:8000`

### 3. Load Chrome Extension

1. Open Chrome and go to `chrome://extensions/`
2. Enable "Developer mode" (toggle in top right)
3. Click "Load unpacked"
4. Select the `extension` folder
5. Extension should appear in your toolbar

### 4. Test It Out

1. Open any YouTube video
2. Press `Alt+Shift+S` to activate overlay
3. Click and drag to select text region
4. Release to capture and extract text
5. Text is auto-copied to clipboard and shown in popup

---

## ğŸ“ Project Structure

```
video_reader/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ preprocessor.py      # Image preprocessing (Otsu + sharpen)
â”‚   â”œâ”€â”€ ocr_engine.py        # Tesseract OCR wrapper
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â””â”€â”€ Dockerfile          # Docker build file
â”œâ”€â”€ extension/
â”‚   â”œâ”€â”€ manifest.json        # Extension configuration
â”‚   â”œâ”€â”€ content.js          # Video detection script
â”‚   â”œâ”€â”€ overlay.js          # Selection UI + frame capture
â”‚   â”œâ”€â”€ background.js       # Backend communication
â”‚   â”œâ”€â”€ popup.html          # Results display
â”‚   â”œâ”€â”€ popup.js            # Popup logic
â”‚   â””â”€â”€ styles.css          # Overlay styling
â””â”€â”€ plans/
    â”œâ”€â”€ blueprint.md                # Original design (accuracy-focused)
    â”œâ”€â”€ blueprint-optimized.md      # Speed-optimized design
    â”œâ”€â”€ blueprint-streaming.md      # Streaming + continuous mode
    â””â”€â”€ WHICH_BLUEPRINT.md          # Blueprint comparison
```

---

## ğŸ”§ Configuration

### Backend API URL

The extension defaults to `http://localhost:8000`. To change:

1. Click extension icon to open popup
2. Scroll to "Settings" section
3. Update "Backend API URL"
4. Connection status will update automatically

### OCR Modes

The backend supports multiple OCR endpoints:

| Endpoint | Speed | Accuracy | Use Case |
|----------|-------|----------|----------|
| `/ocr` (default) |
| `/ocr/accurate`  
| `/ocr/code`
| `/ocr/confidence` 

To use a different mode, modify `background.js`:
```javascript
const response = await fetch(`${API_URL}/ocr/accurate`, { ... });
```

---

## ğŸ¹ Keyboard Shortcuts

- `Alt+Shift+S` - Activate overlay (start selection)
- `Alt+Shift+D` - Deactivate overlay (stop selection)

---

## ğŸ³ Docker Deployment

```bash
cd backend

# Build image
docker build -t video-ocr-backend .

# Run container
docker run -p 8000:8000 video-ocr-backend
```

Access at `http://localhost:8000`

---

## ğŸ“Š Performance Metrics

### Client-Side Processing 
1. Capture video frame:
2. Scale down (if >1000px):
3. Convert to grayscale: 
4. Boost contrast: 
5. Encode to WebP: 

### Network
- Upload size: 2-15KB (grayscale WebP at 0.85 quality)
- Depends on connection speed

### Backend Processing 
1. Otsu threshold:
2. Light sharpen: 
3. Tesseract OCR (OEM 1, PSM 3):

---


## ğŸ“ˆ Optimization Tips

### For Better Speed

1. Use default `/ocr` endpoint (fastest)
2. Keep selections under 1000px width (auto-scales)
3. Use WebP format (already default)
4. Run backend locally (avoid network latency)

### For Better Accuracy

1. Use `/ocr/accurate` endpoint
2. Pause video before capturing (avoid motion blur)
3. Select text-only regions (no backgrounds)
4. Use HD video when possible
5. Increase contrast in video player if text is faint

---

## ğŸ› ï¸ Development

### Run Backend in Development Mode

```bash
cd backend
uvicorn main:app --reload --log-level debug
```

### Test Backend API

```bash
# Health check
curl http://localhost:8000/health

# Test OCR with image
curl -X POST http://localhost:8000/ocr \
  -F "file=@test_image.png"
```

### Reload Extension

After making changes to extension code:
1. Go to `chrome://extensions/`
2. Click reload icon on your extension
3. Refresh any open video pages

---

## ğŸ“ API Documentation

Once backend is running, visit:
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

---

## ğŸ”’ Privacy & Security

- âœ… No data storage (all processing in-memory)
- âœ… No analytics or tracking
- âœ… No external API calls
- âœ… Runs locally on your machine
- âœ… No user accounts or authentication
- âœ… Images deleted immediately after processing

---

## ğŸš§ Known Limitations

- Motion blur: May reduce accuracy if video is playing
- Very small text: OCR accuracy drops for text <16px height
- Handwriting: Not optimized for handwritten text
- Complex backgrounds: Works best with solid backgrounds
- Non-Latin characters: Requires additional Tesseract language packs

---

## ğŸ¯ Future Enhancements

See `plans/blueprint-streaming.md` for planned features:

- [ ] WebSocket connection (eliminate connection overhead)
- [ ] Continuous monitoring mode (auto-capture when text changes)
- [ ] Burst capture mode (rapid multiple selections)
- [ ] Motion handling (multi-frame capture for sharpness)
- [ ] Request queue with worker pool
- [ ] Progressive OCR (show quick preview, then full result)

---

## ğŸ“„ License

MIT License - see LICENSE file for details

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

---

## ğŸ“§ Support

For issues or questions:
1. Check troubleshooting section above
2. Review API docs at `/docs`
3. Open an issue on GitHub

---

## âš¡ Quick Command Reference

```bash
# Backend
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --reload

# Docker
docker build -t video-ocr-backend .
docker run -p 8000:8000 video-ocr-backend

# Test
curl http://localhost:8000/health
curl -X POST http://localhost:8000/ocr -F "file=@image.png"
```

---

**Made with âš¡ for speed and ğŸ¯ for accuracy**
