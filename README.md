# ‚ö° Fast Video OCR - Extract Text from Video Frames

Speed-optimized Chrome extension + Python backend for extracting text from video frames using Tesseract OCR.

**Performance:** 100-225ms total (client + network + OCR)
**Accuracy:** 88-92% for SD/720p video, 92-95% for HD
**Architecture:** Deterministic, privacy-focused, no AI/ML

---

## üìã Features

- ‚úÖ Extract text from any HTML5 video (YouTube, Twitch, Zoom, local files)
- ‚úÖ Client-side preprocessing (grayscale + contrast) for 66% smaller uploads
- ‚úÖ Fast Tesseract OCR (40-80ms processing time)
- ‚úÖ Auto-copy to clipboard
- ‚úÖ Keyboard shortcuts (Alt+Shift+S to activate)
- ‚úÖ Works with SD/720p and HD video
- ‚úÖ Privacy-focused (no data storage, no analytics)

---

## üöÄ Quick Start

### Prerequisites

- Python 3.10+ with pip
- Tesseract OCR 5.x
- Chrome/Chromium browser
- Node.js (optional, for development)

### 1. Install Tesseract OCR

**Ubuntu/Debian:**
```bash
sudo apt-get update
sudo apt-get install tesseract-ocr tesseract-ocr-eng libtesseract-dev
```

**macOS:**
```bash
brew install tesseract
```

**Windows:**
Download installer from https://github.com/UB-Mannheim/tesseract/wiki

Verify installation:
```bash
tesseract --version
```

### 2. Setup Backend

```bash
cd backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run server
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

Backend will start at `http://localhost:8000`

### 3. Load Chrome Extension

1. Open Chrome and go to `chrome://extensions/`
2. Enable "Developer mode" (toggle in top right)
3. Click "Load unpacked"
4. Select the `extension` folder
5. Extension should appear in your toolbar

### 4. Test It Out

1. Open any YouTube video
2. Press `Alt+Shift+S` to activate overlay
3. Click and drag to select text region
4. Release to capture and extract text
5. Text is auto-copied to clipboard and shown in popup

---

## üìÅ Project Structure

```
video_reader/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.py      # Image preprocessing (Otsu + sharpen)
‚îÇ   ‚îú‚îÄ‚îÄ ocr_engine.py        # Tesseract OCR wrapper
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile          # Docker build file
‚îú‚îÄ‚îÄ extension/
‚îÇ   ‚îú‚îÄ‚îÄ manifest.json        # Extension configuration
‚îÇ   ‚îú‚îÄ‚îÄ content.js          # Video detection script
‚îÇ   ‚îú‚îÄ‚îÄ overlay.js          # Selection UI + frame capture
‚îÇ   ‚îú‚îÄ‚îÄ background.js       # Backend communication
‚îÇ   ‚îú‚îÄ‚îÄ popup.html          # Results display
‚îÇ   ‚îú‚îÄ‚îÄ popup.js            # Popup logic
‚îÇ   ‚îî‚îÄ‚îÄ styles.css          # Overlay styling
‚îî‚îÄ‚îÄ plans/
    ‚îú‚îÄ‚îÄ blueprint.md                # Original design (accuracy-focused)
    ‚îú‚îÄ‚îÄ blueprint-optimized.md      # Speed-optimized design
    ‚îú‚îÄ‚îÄ blueprint-streaming.md      # Streaming + continuous mode
    ‚îî‚îÄ‚îÄ WHICH_BLUEPRINT.md          # Blueprint comparison
```

---

## üîß Configuration

### Backend API URL

The extension defaults to `http://localhost:8000`. To change:

1. Click extension icon to open popup
2. Scroll to "Settings" section
3. Update "Backend API URL"
4. Connection status will update automatically

### OCR Modes

The backend supports multiple OCR endpoints:

| Endpoint | Speed | Accuracy | Use Case |
|----------|-------|----------|----------|
| `/ocr` (default) | ~50-95ms | 88-92% | Fast, general purpose |
| `/ocr/accurate` | ~80-150ms | 92-95% | Higher accuracy |
| `/ocr/code` | ~50-95ms | 88-92% | Preserves indentation |
| `/ocr/confidence` | ~60-110ms | 88-92% | Returns confidence scores |

To use a different mode, modify `background.js`:
```javascript
const response = await fetch(`${API_URL}/ocr/accurate`, { ... });
```

---

## üéπ Keyboard Shortcuts

- `Alt+Shift+S` - Activate overlay (start selection)
- `Alt+Shift+D` - Deactivate overlay (stop selection)

---

## üê≥ Docker Deployment

```bash
cd backend

# Build image
docker build -t video-ocr-backend .

# Run container
docker run -p 8000:8000 video-ocr-backend
```

Access at `http://localhost:8000`

---

## üìä Performance Metrics

### Client-Side Processing (~30ms)
1. Capture video frame: ~10ms
2. Scale down (if >1000px): ~5ms
3. Convert to grayscale: ~5ms
4. Boost contrast: ~3ms
5. Encode to WebP: ~12ms

### Network (~20-80ms)
- Upload size: 2-15KB (grayscale WebP at 0.85 quality)
- Depends on connection speed

### Backend Processing (~50-95ms)
1. Otsu threshold: ~5ms
2. Light sharpen: ~10ms
3. Tesseract OCR (OEM 1, PSM 3): ~50ms

**Total: 100-225ms** (average: ~170ms)

---

## üîç Troubleshooting

### "Cannot connect to backend"

1. Check backend is running: `curl http://localhost:8000/health`
2. Check firewall/port 8000 is open
3. Verify API URL in extension settings

### "Tesseract not found"

1. Verify Tesseract is installed: `tesseract --version`
2. Check it's in PATH: `which tesseract` (Linux/Mac)
3. Restart terminal after installation

### Low OCR Accuracy

1. Use `/ocr/accurate` endpoint for better results
2. Increase video quality (HD instead of SD)
3. Select larger text regions
4. Ensure text is clearly visible (pause video if blurry)

### Extension Not Working

1. Check console for errors (F12 ‚Üí Console)
2. Reload extension in `chrome://extensions/`
3. Refresh the video page
4. Check extension has permissions for the site

---

## üìà Optimization Tips

### For Better Speed

1. Use default `/ocr` endpoint (fastest)
2. Keep selections under 1000px width (auto-scales)
3. Use WebP format (already default)
4. Run backend locally (avoid network latency)

### For Better Accuracy

1. Use `/ocr/accurate` endpoint
2. Pause video before capturing (avoid motion blur)
3. Select text-only regions (no backgrounds)
4. Use HD video when possible
5. Increase contrast in video player if text is faint

---

## üõ†Ô∏è Development

### Run Backend in Development Mode

```bash
cd backend
uvicorn main:app --reload --log-level debug
```

### Test Backend API

```bash
# Health check
curl http://localhost:8000/health

# Test OCR with image
curl -X POST http://localhost:8000/ocr \
  -F "file=@test_image.png"
```

### Reload Extension

After making changes to extension code:
1. Go to `chrome://extensions/`
2. Click reload icon on your extension
3. Refresh any open video pages

---

## üìù API Documentation

Once backend is running, visit:
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

---

## üîí Privacy & Security

- ‚úÖ No data storage (all processing in-memory)
- ‚úÖ No analytics or tracking
- ‚úÖ No external API calls
- ‚úÖ Runs locally on your machine
- ‚úÖ No user accounts or authentication
- ‚úÖ Images deleted immediately after processing

---

## üöß Known Limitations

- Motion blur: May reduce accuracy if video is playing
- Very small text: OCR accuracy drops for text <16px height
- Handwriting: Not optimized for handwritten text
- Complex backgrounds: Works best with solid backgrounds
- Non-Latin characters: Requires additional Tesseract language packs

---

## üéØ Future Enhancements

See `plans/blueprint-streaming.md` for planned features:

- [ ] WebSocket connection (eliminate connection overhead)
- [ ] Continuous monitoring mode (auto-capture when text changes)
- [ ] Burst capture mode (rapid multiple selections)
- [ ] Motion handling (multi-frame capture for sharpness)
- [ ] Request queue with worker pool
- [ ] Progressive OCR (show quick preview, then full result)

---

## üìÑ License

MIT License - see LICENSE file for details

---

## ü§ù Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

---

## üìß Support

For issues or questions:
1. Check troubleshooting section above
2. Review API docs at `/docs`
3. Open an issue on GitHub

---

## ‚ö° Quick Command Reference

```bash
# Backend
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --reload

# Docker
docker build -t video-ocr-backend .
docker run -p 8000:8000 video-ocr-backend

# Test
curl http://localhost:8000/health
curl -X POST http://localhost:8000/ocr -F "file=@image.png"
```

---

**Made with ‚ö° for speed and üéØ for accuracy**
